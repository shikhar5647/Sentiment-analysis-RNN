{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vN_L4URCGhdt"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense,SimpleRNN,Embedding,Flatten"
      ],
      "metadata": {
        "id": "ZDJ6v1j7GkhV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test)=imdb.load_data()"
      ],
      "metadata": {
        "id": "AtfFHhmfGwbj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is already preprocessed and integer encoded"
      ],
      "metadata": {
        "id": "0Rm-USjvHYX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAQNCx7kG6mU",
        "outputId": "1cc8153a-5ac4-4171-d538-b80af93a5a1b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "       ...,\n",
              "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLj-vbjkG9Rx",
        "outputId": "e85571bc-aa76-4445-ff88-9fa0b6bec011"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P0SynJEHA6m",
        "outputId": "5be5d991-ca73-42b0-e125-01c95b7b12a6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDNsGWkXHDFv",
        "outputId": "c6a8d5f1-ce1b-4023-8b3f-ac26b2eb8866"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLtSx0sQHkLE",
        "outputId": "686c7e9b-6a85-4905-a0fb-8aad5f8d6da5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As the size is quite different for each review, we are using padding\n",
        "from keras.utils import pad_sequences\n",
        "X_train=pad_sequences(X_train,padding='post',maxlen=50)\n",
        "X_test=pad_sequences(X_test,padding='post',maxlen=50)"
      ],
      "metadata": {
        "id": "cHb1qrWKH1Jx"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naw7IaR0IY-p",
        "outputId": "a60a89a3-3b02-4edc-883a-b8389e4735d6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH6OdvK2IbQ1",
        "outputId": "c79352a0-16fa-4646-f674-53a1696cd723"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(SimpleRNN(64,input_shape=(50,1),return_sequences=False))# false as we want the output of the last timestamp\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCM7z0Z_Idmu",
        "outputId": "218d9a4f-220a-423a-b783-fb3f5e3e29a9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_14 (SimpleRNN)   (None, 64)                4224      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4289 (16.75 KB)\n",
            "Trainable params: 4289 (16.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6LFgMO5KKaa",
        "outputId": "17d1e813-0555-4215-ea6a-1bfddecbec81"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 21s 26ms/step - loss: 0.6945 - accuracy: 0.5105 - val_loss: 0.6945 - val_accuracy: 0.5056\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 21s 27ms/step - loss: 0.6943 - accuracy: 0.5068 - val_loss: 0.6946 - val_accuracy: 0.5098\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 0.6943 - accuracy: 0.5055 - val_loss: 0.6930 - val_accuracy: 0.5099\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 21s 26ms/step - loss: 0.6942 - accuracy: 0.5083 - val_loss: 0.6936 - val_accuracy: 0.5052\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 20s 25ms/step - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6939 - val_accuracy: 0.5063\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 20s 26ms/step - loss: 0.6931 - accuracy: 0.5130 - val_loss: 0.6956 - val_accuracy: 0.5088\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 19s 25ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6934 - val_accuracy: 0.5141\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 0.6935 - accuracy: 0.5134 - val_loss: 0.6929 - val_accuracy: 0.5112\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 21s 27ms/step - loss: 0.6934 - accuracy: 0.5068 - val_loss: 0.6932 - val_accuracy: 0.5037\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 0.6929 - accuracy: 0.5172 - val_loss: 0.6927 - val_accuracy: 0.5107\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dd2b2b76e30>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMAK1UwQ5lKJ",
        "outputId": "dd2a393a-c19a-4e90-c5f5-9bbae1e5a527"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 8ms/step - loss: 0.5037 - accuracy: 0.7656\n",
            "Test Accuracy: 0.76555997133255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding will give better results as compared to the earlier method.In NLP , word embeddings is a term used for the represenatation of words for text analysis , in the form of real-valued vectors that encode the meaning of the words such that words that are closer in the vector space are expected to be similar in meaning."
      ],
      "metadata": {
        "id": "YHaFn8sHMXKK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec and Glove are embedding technique only"
      ],
      "metadata": {
        "id": "jGOMXjYto7QC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Embedding(input_dim=15000, output_dim=32, input_length=100))\n",
        "model2.add(SimpleRNN(units=64))\n",
        "model2.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "loss, accuracy = model2.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2dp1Gt_x5cS",
        "outputId": "a568d448-f220-4b9b-a51b-2be465888f84"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 10s 57ms/step - loss: 0.6629 - accuracy: 0.5775 - val_loss: 0.5822 - val_accuracy: 0.7166\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 7s 45ms/step - loss: 0.3951 - accuracy: 0.8267 - val_loss: 0.4325 - val_accuracy: 0.8036\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 8s 53ms/step - loss: 0.2521 - accuracy: 0.9003 - val_loss: 0.4882 - val_accuracy: 0.8036\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 8s 52ms/step - loss: 0.1501 - accuracy: 0.9462 - val_loss: 0.5026 - val_accuracy: 0.7948\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 7s 46ms/step - loss: 0.0711 - accuracy: 0.9780 - val_loss: 0.6355 - val_accuracy: 0.8110\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 9s 60ms/step - loss: 0.0487 - accuracy: 0.9862 - val_loss: 0.6341 - val_accuracy: 0.7990\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 7s 45ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.7431 - val_accuracy: 0.8218\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 8s 53ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.8146 - val_accuracy: 0.8210\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 8s 49ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.8429 - val_accuracy: 0.8184\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 7s 47ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.8822 - val_accuracy: 0.8196\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9009 - accuracy: 0.8083\n",
            "Test Accuracy: 0.8082799911499023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jok8eY8e4yts"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}